{
  "version": 3,
  "sources": ["../../../../../src/trigger/docs.ts", "../../../../../src/lib/mintlify.ts"],
  "sourcesContent": ["import { schedules } from \"@trigger.dev/sdk\";\nimport { prisma } from \"@/lib/prisma\";\nimport { getRepoFileContent } from \"@/lib/github\";\nimport { generateEmbedding } from \"@/lib/ai\";\nimport { getMintlifyPages } from \"@/lib/mintlify\";\nimport crypto from \"node:crypto\";\nimport path from \"path\";\n\n// Simple chunking by H2 headers\n// Note: In a production app, use a more robust splitter (e.g. by recursive character count or markdown structure)\nfunction chunkMarkdown(\n  content: string\n): { heading: string; content: string }[] {\n  const chunks: { heading: string; content: string }[] = [];\n  const lines = content.split(\"\\n\");\n  let currentHeading = \"Introduction\";\n  let currentBuffer: string[] = [];\n\n  for (const line of lines) {\n    if (line.startsWith(\"## \")) {\n      if (currentBuffer.length > 0) {\n        chunks.push({\n          heading: currentHeading,\n          content: currentBuffer.join(\"\\n\"),\n        });\n      }\n      currentHeading = line.replace(\"## \", \"\").trim();\n      currentBuffer = [];\n    } else {\n      currentBuffer.push(line);\n    }\n  }\n  if (currentBuffer.length > 0) {\n    chunks.push({ heading: currentHeading, content: currentBuffer.join(\"\\n\") });\n  }\n\n  return chunks;\n}\n\nexport const ingestDocs = schedules.task({\n  id: \"ingest-docs\",\n  cron: \"0 */6 * * *\", // Every 6 hours\n  run: async () => {\n    const owner = process.env.GITHUB_OWNER;\n    const repo = process.env.GITHUB_REPO;\n    const configPath = process.env.DOCS_CONFIG_PATH || \"mint.json\";\n\n    if (!owner || !repo) {\n      throw new Error(\"GITHUB_OWNER and GITHUB_REPO env vars must be set\");\n    }\n\n    let totalChunks = 0;\n\n    // Determine base path for docs (relative to repo root)\n    // If config is at \"docs/mint.json\", base path is \"docs/\"\n    const docsRoot = path.dirname(configPath);\n\n    // 1. Get list of pages from Mintlify config\n    const pages = await getMintlifyPages(owner, repo, configPath);\n    if (pages.length === 0) {\n      console.log(\"No pages found in Mintlify config or config missing.\");\n      return { processed: 0 };\n    }\n\n    // 2. Iterate and fetch content\n    for (const page of pages) {\n      // Construct full path based on docs root\n      // Mintlify pages are relative to the config file location usually\n      const fullPagePath = path.join(docsRoot, page);\n\n      // Mintlify pages often omit extension in config, try .mdx then .md\n      let filePath = fullPagePath;\n      if (!filePath.endsWith(\".md\") && !filePath.endsWith(\".mdx\")) {\n        filePath += \".mdx\";\n      }\n\n      let content = await getRepoFileContent(owner, repo, filePath);\n      if (!content) {\n        // Try .md\n        filePath = fullPagePath + \".md\";\n        content = await getRepoFileContent(owner, repo, filePath);\n      }\n\n      if (!content) {\n        console.warn(\n          `Could not find content for page: ${page} (tried ${filePath})`\n        );\n        continue;\n      }\n\n      const chunks = chunkMarkdown(content);\n\n      for (const chunk of chunks) {\n        const hash = crypto\n          .createHash(\"sha256\")\n          .update(filePath + chunk.content)\n          .digest(\"hex\");\n\n        // Check if chunk exists and hasn't changed\n        const existing = await prisma.docChunk.findFirst({\n          where: { hash },\n        });\n\n        if (!existing) {\n          const embedding = await generateEmbedding(\n            `${chunk.heading}\\n${chunk.content}`\n          );\n          // Format embedding for pgvector\n          const embeddingString = `[${embedding.join(\",\")}]`;\n\n          // Delete old chunks for this path/heading to avoid stale data if content changed\n          await prisma.docChunk.deleteMany({\n            where: {\n              sourcePath: filePath,\n              heading: chunk.heading,\n              NOT: { hash }, // Don't delete if we just inserted it (edge case)\n            },\n          });\n\n          // Using raw query for vector insertion until Prisma fully supports it\n          await prisma.$executeRaw`\n                        INSERT INTO \"DocChunk\" (id, source, \"sourcePath\", heading, content, hash, embedding, \"createdAt\", \"updatedAt\")\n                        VALUES (gen_random_uuid(), 'docs', ${filePath}, ${chunk.heading}, ${chunk.content}, ${hash}, ${embeddingString}::vector, NOW(), NOW())\n                    `;\n\n          totalChunks++;\n        }\n      }\n    }\n\n    return { processed: totalChunks };\n  },\n});\n", "import { getRepoFileContent } from \"./github\";\n\ntype MintlifyPage = string; // \"group/page\"\n\ntype MintlifyGroup = {\n  group: string;\n  pages: (MintlifyPage | MintlifyGroup)[];\n};\n\ntype MintlifyDropdown = {\n  dropdown: string;\n  groups: MintlifyGroup[];\n};\n\ntype MintlifyNavigation = \n  | (MintlifyGroup | MintlifyPage)[]\n  | { dropdowns: MintlifyDropdown[] };\n\ntype MintlifyConfig = {\n  navigation: MintlifyNavigation;\n  // other fields ignored for now\n};\n\nexport async function getMintlifyPages(owner: string, repo: string, configPath: string): Promise<string[]> {\n  try {\n    const content = await getRepoFileContent(owner, repo, configPath);\n    if (!content) {\n      console.warn(`Mintlify config not found at ${configPath}`);\n      return [];\n    }\n\n    const config = JSON.parse(content) as MintlifyConfig;\n    return extractPages(config.navigation);\n  } catch (error) {\n    console.error(\"Error parsing Mintlify config:\", error);\n    return [];\n  }\n}\n\nfunction extractPages(nav: MintlifyNavigation | MintlifyDropdown[] | MintlifyGroup[]): string[] {\n  let pages: string[] = [];\n  \n  // Handle { dropdowns: [...] } object style\n  if (!Array.isArray(nav) && typeof nav === \"object\" && \"dropdowns\" in nav) {\n    return extractPages(nav.dropdowns);\n  }\n\n  // Handle array style (dropdowns, groups, or pages)\n  if (Array.isArray(nav)) {\n    for (const item of nav) {\n      if (typeof item === \"string\") {\n        // It's a page path\n        pages.push(item);\n      } else if (typeof item === \"object\") {\n        if (\"dropdown\" in item && item.groups) {\n            // It's a dropdown\n            pages = pages.concat(extractPages(item.groups));\n        } else if (\"group\" in item && item.pages) {\n            // It's a group\n            pages = pages.concat(extractPages(item.pages));\n        }\n      }\n    }\n  }\n  \n  return pages;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;AAAA;;;ACAA;AAuBA,eAAsB,iBAAiB,OAAe,MAAc,YAAuC;AACzG,MAAI;AACF,UAAM,UAAU,MAAM,mBAAmB,OAAO,MAAM,UAAU;AAChE,QAAI,CAAC,SAAS;AACZ,cAAQ,KAAK,gCAAgC,UAAU,EAAE;AACzD,aAAO,CAAC;AAAA,IACV;AAEA,UAAM,SAAS,KAAK,MAAM,OAAO;AACjC,WAAO,aAAa,OAAO,UAAU;AAAA,EACvC,SAAS,OAAO;AACd,YAAQ,MAAM,kCAAkC,KAAK;AACrD,WAAO,CAAC;AAAA,EACV;AACF;AAdsB;AAgBtB,SAAS,aAAa,KAA0E;AAC9F,MAAI,QAAkB,CAAC;AAGvB,MAAI,CAAC,MAAM,QAAQ,GAAG,KAAK,OAAO,QAAQ,YAAY,eAAe,KAAK;AACxE,WAAO,aAAa,IAAI,SAAS;AAAA,EACnC;AAGA,MAAI,MAAM,QAAQ,GAAG,GAAG;AACtB,eAAW,QAAQ,KAAK;AACtB,UAAI,OAAO,SAAS,UAAU;AAE5B,cAAM,KAAK,IAAI;AAAA,MACjB,WAAW,OAAO,SAAS,UAAU;AACnC,YAAI,cAAc,QAAQ,KAAK,QAAQ;AAEnC,kBAAQ,MAAM,OAAO,aAAa,KAAK,MAAM,CAAC;AAAA,QAClD,WAAW,WAAW,QAAQ,KAAK,OAAO;AAEtC,kBAAQ,MAAM,OAAO,aAAa,KAAK,KAAK,CAAC;AAAA,QACjD;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AA3BS;;;ADlCT,OAAO,YAAY;AACnB,OAAO,UAAU;AAIjB,SAAS,cACP,SACwC;AACxC,QAAM,SAAiD,CAAC;AACxD,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,MAAI,iBAAiB;AACrB,MAAI,gBAA0B,CAAC;AAE/B,aAAW,QAAQ,OAAO;AACxB,QAAI,KAAK,WAAW,KAAK,GAAG;AAC1B,UAAI,cAAc,SAAS,GAAG;AAC5B,eAAO,KAAK;AAAA,UACV,SAAS;AAAA,UACT,SAAS,cAAc,KAAK,IAAI;AAAA,QAClC,CAAC;AAAA,MACH;AACA,uBAAiB,KAAK,QAAQ,OAAO,EAAE,EAAE,KAAK;AAC9C,sBAAgB,CAAC;AAAA,IACnB,OAAO;AACL,oBAAc,KAAK,IAAI;AAAA,IACzB;AAAA,EACF;AACA,MAAI,cAAc,SAAS,GAAG;AAC5B,WAAO,KAAK,EAAE,SAAS,gBAAgB,SAAS,cAAc,KAAK,IAAI,EAAE,CAAC;AAAA,EAC5E;AAEA,SAAO;AACT;AA3BS;AA6BF,IAAM,aAAa,kBAAU,KAAK;AAAA,EACvC,IAAI;AAAA,EACJ,MAAM;AAAA;AAAA,EACN,KAAK,mCAAY;AACf,UAAM,QAAQ,QAAQ,IAAI;AAC1B,UAAM,OAAO,QAAQ,IAAI;AACzB,UAAM,aAAa,QAAQ,IAAI,oBAAoB;AAEnD,QAAI,CAAC,SAAS,CAAC,MAAM;AACnB,YAAM,IAAI,MAAM,mDAAmD;AAAA,IACrE;AAEA,QAAI,cAAc;AAIlB,UAAM,WAAW,KAAK,QAAQ,UAAU;AAGxC,UAAM,QAAQ,MAAM,iBAAiB,OAAO,MAAM,UAAU;AAC5D,QAAI,MAAM,WAAW,GAAG;AACtB,cAAQ,IAAI,sDAAsD;AAClE,aAAO,EAAE,WAAW,EAAE;AAAA,IACxB;AAGA,eAAW,QAAQ,OAAO;AAGxB,YAAM,eAAe,KAAK,KAAK,UAAU,IAAI;AAG7C,UAAI,WAAW;AACf,UAAI,CAAC,SAAS,SAAS,KAAK,KAAK,CAAC,SAAS,SAAS,MAAM,GAAG;AAC3D,oBAAY;AAAA,MACd;AAEA,UAAI,UAAU,MAAM,mBAAmB,OAAO,MAAM,QAAQ;AAC5D,UAAI,CAAC,SAAS;AAEZ,mBAAW,eAAe;AAC1B,kBAAU,MAAM,mBAAmB,OAAO,MAAM,QAAQ;AAAA,MAC1D;AAEA,UAAI,CAAC,SAAS;AACZ,gBAAQ;AAAA,UACN,oCAAoC,IAAI,WAAW,QAAQ;AAAA,QAC7D;AACA;AAAA,MACF;AAEA,YAAM,SAAS,cAAc,OAAO;AAEpC,iBAAW,SAAS,QAAQ;AAC1B,cAAM,OAAO,OACV,WAAW,QAAQ,EACnB,OAAO,WAAW,MAAM,OAAO,EAC/B,OAAO,KAAK;AAGf,cAAM,WAAW,MAAM,OAAO,SAAS,UAAU;AAAA,UAC/C,OAAO,EAAE,KAAK;AAAA,QAChB,CAAC;AAED,YAAI,CAAC,UAAU;AACb,gBAAM,YAAY,MAAM;AAAA,YACtB,GAAG,MAAM,OAAO;AAAA,EAAK,MAAM,OAAO;AAAA,UACpC;AAEA,gBAAM,kBAAkB,IAAI,UAAU,KAAK,GAAG,CAAC;AAG/C,gBAAM,OAAO,SAAS,WAAW;AAAA,YAC/B,OAAO;AAAA,cACL,YAAY;AAAA,cACZ,SAAS,MAAM;AAAA,cACf,KAAK,EAAE,KAAK;AAAA;AAAA,YACd;AAAA,UACF,CAAC;AAGD,gBAAM,OAAO;AAAA;AAAA,6DAEsC,QAAQ,KAAK,MAAM,OAAO,KAAK,MAAM,OAAO,KAAK,IAAI,KAAK,eAAe;AAAA;AAG5H;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,WAAO,EAAE,WAAW,YAAY;AAAA,EAClC,GAzFK;AA0FP,CAAC;",
  "names": []
}
